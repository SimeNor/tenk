{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "57429d3b74827d702e8e2e5791ec7a19d83902ac9a4758c7d15f370d77f1cb81"
    },
    "kernelspec": {
      "display_name": "Python 3.6.8 64-bit ('tenk_env': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "TENK_pytorch.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4h2ENDTx0so"
      },
      "source": [
        "Kjøre celle for å sette opp systemet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJGgklb7x0sr"
      },
      "source": [
        "!git clone https://github.com/SimeNor/tenk.git\n",
        "\n",
        "import os\n",
        "os.chdir(\"tenk\")\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HunzWpR-kt3w"
      },
      "source": [
        "os.system('unzip cropped.zip && rm uncropped.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQPzvelGx0ss"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "meta = pd.read_csv(\"imdb.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tPou7XmIIim"
      },
      "source": [
        "popDf = pd.DataFrame(meta[meta.photo_taken>2010].name.value_counts(), columns=['name'])\n",
        "topCelebs = meta[(meta[\"face_score\"] > 4) & (np.isnan(meta[\"second_face_score\"])) & meta[\"name\"].isin(list(popDf[popDf.name>30].index))]\n",
        "topCelebs.to_csv(\"topCelebs30.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZCIShDNKzgW"
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def display_random_images(metadata, num_images=6):\n",
        "    # create figure\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # setting values to rows and column variables\n",
        "    rows = int(math.ceil(num_images / 2))\n",
        "    columns = 2\n",
        "    # reading images\n",
        "    sample = metadata.sample(n=num_images)\n",
        "    filenames = sample.full_path\n",
        "    celebs = sample.name\n",
        "    face_score = sample.face_score\n",
        "    # Adds a subplot at the 1st position\n",
        "    for i, filepath in enumerate(filenames):\n",
        "        try:\n",
        "            fig.add_subplot(rows, columns, i + 1)\n",
        "            img = cv2.cvtColor(cv2.imread(f'imdb_crop/{filepath}'), cv2.COLOR_BGR2RGB)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"{celebs.iloc[i]}, {face_score.iloc[i]}\")\n",
        "        except:\n",
        "            print(filepath, f\"{celebs.iloc[i]}, {face_score.iloc[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iHJmGyIKzkR"
      },
      "source": [
        "from utils import \n",
        "\n",
        "display_random_images(topCelebs, num_images=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tboJ966row3"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if not os.path.isdir(f\"Celebs\"):\n",
        "        os.mkdir(f\"Celebs\")\n",
        "\n",
        "for i, row in topCelebs.iterrows():\n",
        "    if not os.path.isdir(f\"Celebs/{row.celeb_id}/\"):\n",
        "        os.mkdir(f\"Celebs/{row.celeb_id}\")\n",
        "    shutil.copy2(\"imdb_crop/\"+row.full_path, f\"Celebs/{row.celeb_id}/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eH_KVKESvqR"
      },
      "source": [
        "## Init cropping-model and set parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ1LnUPUklW4"
      },
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Xc1SDKtMCu"
      },
      "source": [
        "data_dir = 'Celebs'\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 8\n",
        "workers = 0 if os.name == 'nt' else 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTDKNv7AtL5M"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAEtefwEtV6c"
      },
      "source": [
        "mtcnn = MTCNN(\n",
        "    image_size=160, margin=5, min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-TXqlCPS4bS"
      },
      "source": [
        "### Extract and load cropped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbBuMgHoeAKd"
      },
      "source": [
        "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
        "dataset.samples = [\n",
        "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
        "        for p, _ in dataset.samples\n",
        "]\n",
        "        \n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=training.collate_pil\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQYkBrQxtVyt"
      },
      "source": [
        "\n",
        "for i, (x, y) in enumerate(loader):\n",
        "    mtcnn(x, save_path=y)\n",
        "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
        "    \n",
        "# Remove mtcnn to reduce GPU memory usage\n",
        "del mtcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9M0gbfZO3ZB"
      },
      "source": [
        "\"\"\"\n",
        "!zip -r cropped.zip Celebs_cropped\n",
        "!zip -r uncropped.zip Celebs\n",
        "\n",
        "\n",
        "\n",
        "def upload_to_s3():\n",
        "    import boto3\n",
        "    import os\n",
        "\n",
        "    BUCKET_NAME = 'celebfaces' # replace with your bucket name\n",
        "\n",
        "    # enter authentication credentials\n",
        "    s3 = boto3.resource('s3',\n",
        "                        aws_access_key_id='',\n",
        "                        aws_secret_access_key='')\n",
        "\n",
        "    s3.Bucket(BUCKET_NAME).upload_file('cropped.zip', 'cropped.zip')\n",
        "    s3.Bucket(BUCKET_NAME).upload_file('uncropped.zip', 'uncropped.zip')\n",
        "\n",
        "upload_to_s3()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhum9FaLTGmP"
      },
      "source": [
        "### Init ID-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ffQfMWoTL7a"
      },
      "source": [
        "resnet = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(dataset.class_to_idx)\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clYWivTVwwb_"
      },
      "source": [
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "scheduler = MultiStepLR(optimizer, [5, 10])\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    np.float32,\n",
        "    transforms.ToTensor(),\n",
        "    fixed_image_standardization\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir + '_cropped', transform=trans)\n",
        "img_inds = np.arange(len(dataset))\n",
        "np.random.shuffle(img_inds)\n",
        "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
        "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_inds)\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset,\n",
        "    num_workers=workers,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_inds)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz-ekoFpwwYc"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metrics = {\n",
        "    'fps': training.BatchTimer(),\n",
        "    'acc': training.accuracy\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x67f6HXbTXDS"
      },
      "source": [
        "### Train ID-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81zoCd37wwU1"
      },
      "source": [
        "writer = SummaryWriter()\n",
        "writer.iteration, writer.interval = 0, 1\n",
        "\n",
        "resnet.eval()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    resnet.train()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "    resnet.eval()\n",
        "    training.pass_epoch(\n",
        "        resnet, loss_fn, val_loader,\n",
        "        batch_metrics=metrics, show_running=True, device=device,\n",
        "        writer=writer\n",
        "    )\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7as8Vo0YwwNx"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JlQSmgdMx2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--9hEqa_Xcf-"
      },
      "source": [
        "def collate_fn(x):\n",
        "    return x[0]\n",
        "\n",
        "test_dataset = datasets.ImageFolder('Celebs_cropped')\n",
        "test_dataset.idx_to_class = {i:c for c, i in test_dataset.class_to_idx.items()}\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, num_workers=workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUuqOzEHXcZx"
      },
      "source": [
        "from torchvision.transforms import functional as F\n",
        "\n",
        "aligned = []\n",
        "names = []\n",
        "for x, y in test_loader:\n",
        "    aligned.append(F.to_tensor(np.float32(x)))\n",
        "    names.append(test_dataset.idx_to_class[y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okB_813nXcPA"
      },
      "source": [
        "aligned = torch.stack(aligned).to(device)\n",
        "embeddings = resnet(aligned).detach().cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IhhUbuVeWgT"
      },
      "source": [
        "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
        "resdf = pd.DataFrame(dists, columns=names, index=names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}